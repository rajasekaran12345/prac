import numpy as np

# 1. Generate a simple dataset (X: 2 features, y: 0/1 labels)
np.random.seed(42)
X = np.random.randn(200, 2)  # 200 samples, 2 features
y = (X[:, 0] * X[:, 1] > 0).astype(int).reshape(-1, 1)  # label = 1 if product > 0 else 0

# 2. Define network architecture
input_size = 2
hidden_size = 4
output_size = 1
learning_rate = 0.1
epochs = 1000

# 3. Initialize weights
W1 = np.random.randn(input_size, hidden_size)
b1 = np.zeros((1, hidden_size))
W2 = np.random.randn(hidden_size, output_size)
b2 = np.zeros((1, output_size))

# Sigmoid activation
def sigmoid(z): return 1 / (1 + np.exp(-z))
def sigmoid_deriv(z): return sigmoid(z) * (1 - sigmoid(z))

# 4. Training loop
for epoch in range(epochs):
    # Forward pass
    z1 = X.dot(W1) + b1
    a1 = np.tanh(z1)  # hidden layer activation
    z2 = a1.dot(W2) + b2
    a2 = sigmoid(z2)  # output layer activation (probability)

    # Compute loss (binary cross-entropy)
    loss = -np.mean(y * np.log(a2 + 1e-8) + (1 - y) * np.log(1 - a2 + 1e-8))

    # Backpropagation
    dz2 = a2 - y
    dW2 = a1.T.dot(dz2) / len(X)
    db2 = np.mean(dz2, axis=0, keepdims=True)

    dz1 = dz2.dot(W2.T) * (1 - np.tanh(z1) ** 2)
    dW1 = X.T.dot(dz1) / len(X)
    db1 = np.mean(dz1, axis=0, keepdims=True)

    # Gradient descent update
    W1 -= learning_rate * dW1
    b1 -= learning_rate * db1
    W2 -= learning_rate * dW2
    b2 -= learning_rate * db2

    # Print loss occasionally
    if epoch % 100 == 0:
        predictions = (a2 > 0.5).astype(int)
        accuracy = np.mean(predictions == y)
        print(f"Epoch {epoch}, Loss: {loss:.4f}, Accuracy: {accuracy:.2f}")

# 5. Final accuracy
predictions = (a2 > 0.5).astype(int)
print("\nFinal Accuracy:", np.mean(predictions == y))
